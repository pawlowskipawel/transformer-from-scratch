# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/vocabulary.ipynb (unless otherwise specified).

__all__ = ['VocabBuilder']

# Cell
from torchtext.data.utils import get_tokenizer
from torchtext import vocab

import torch
import os
import re

# Cell
class VocabBuilder:
    def __init__(self, language, max_vocab_size=50000):

        assert language in ("en", "de"), f"Unknown language: {language}. Supported languages: en, de"
        tokenizer_language = "en_core_web_sm" if language == "en" else "de_core_news_sm"

        self.language = language
        self._tokenizer = get_tokenizer("spacy", language=tokenizer_language)
        self._max_vocab_size = max_vocab_size

        self._pad_token = "<pad>"
        self._unk_token = "<unk>"
        self._sos_token = "<sos>"
        self._eos_token = "<eos>"

        self._vocab = None

    def _yield_tokens(self, texts):
        for text in texts:
            yield self._tokenizer(re.sub(r" +", " ", text))

    def _build_vocab(self, texts, min_freq=5):
        return vocab.build_vocab_from_iterator(self._yield_tokens(texts),
                                               min_freq=min_freq,
                                               max_tokens=self._max_vocab_size,
                                               specials=[self._sos_token, self._eos_token, self._unk_token, self._pad_token])

    def _save_vocab(self, vocab_obj, save_dir):
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        path = os.path.join(save_dir, f"{self.language}.vocab")

        torch.save(vocab_obj, path)

    def get_vocab(self):
        return self._vocab

    def build(self, texts, min_freq=5, lowercase=True, save_dir=None):
        if lowercase:
            texts = [text.lower() for text in texts]

        self._vocab = self._build_vocab(texts, min_freq=min_freq)
        self._vocab.set_default_index(self._vocab[self._unk_token])

        if save_dir:
            self._save_vocab(self._vocab, save_dir)

        return self._vocab