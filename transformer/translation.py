# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/translation.ipynb (unless otherwise specified).

__all__ = ['translate_sentence']

# Cell
import torch

# Cell
def translate_sentence(model, src_sentence, src_tokenizer, trg_tokenizer, max_length=50, device="cuda"):
    model.eval()

    tokenized_sentence = src_tokenizer(src_sentence, return_tensors=True, add_special_tokens=True)
    input_ids = tokenized_sentence["input_ids"].unsqueeze(0).to("cuda")

    translated_sentence = [trg_tokenizer.sos_token_id]

    src_sentence_representation = model.forward_encoder(input_ids)

    for _ in range(max_length):
        translated_sentence_input = torch.tensor(translated_sentence, dtype=torch.long, device=device).unsqueeze(0)

        next_word_id = model.forward_decoder_and_output_layer(src_sentence_representation, translated_sentence_input)[:, -1, :].argmax(1)
        translated_sentence.append(next_word_id.item())

        if next_word_id.item() == trg_tokenizer.eos_token_id:
            return trg_tokenizer.decode(translated_sentence[1: -1])

    return trg_tokenizer.decode(translated_sentence[1:])
